# Introduction {#intro}

You can label chapter and section titles using `{#label}` after them, e.g., we can reference Chapter \@ref(intro). If you do not manually label them, there will be automatic labels anyway, e.g., Chapter \@ref(methods).

Figures and tables with captions will be placed in `figure` and `table` environments, respectively.

```{r nice-fig, fig.cap='Here is a nice figure!', out.width='80%', fig.asp=.75, fig.align='center'}
par(mar = c(4, 4, .1, .1))
plot(pressure, type = 'b', pch = 19)
```

Reference a figure by its code chunk label with the `fig:` prefix, e.g., see Figure \@ref(fig:nice-fig). Similarly, you can reference tables generated from `knitr::kable()`, e.g., see Table \@ref(tab:nice-tab).

```{r nice-tab, tidy=FALSE}
knitr::kable(
  head(iris, 20), caption = 'Here is a nice table!',
  booktabs = TRUE
)
```

You can write citations, too. For example, we are using the **bookdown** package [@R-bookdown] in this sample book, which was built on top of R Markdown and **knitr** [@xie2015].

## Random experiment
This is a deep topic. We can't go into depth here. Human intuition fails. The formal theories [plural (see opening of this text)](https://www.google.co.uk/books/edition/Interpretations_of_Probability/j_2jlgdEIVQC?hl=en&gbpv=1&dq=probability+interpretation&printsec=frontcover) are well established but the interpretations are not. We approach it from a subjective perspective, whether the physical process is random or it just looks random because of your degree of ignorance will be treated the same. We acknowledge randomness exists in the physical world but assume many beginning readers will find it more natural to view it from a subjective perspective - i.e. as a measure of their ignorance.

Examples: deterministic process that can produce a random sequence? It's the mathematical sequence that is random even though underlying physical process is not.

Selecting a person at random and measuring their weight gives a random number. Yet the subject could be certain of their weight all along. It's the selection process that must introduce randomness in the eyes of the researcher. It is subjective - relative to an individuals role in the process as the actual weight is not uncertain.

However, nuclear decay is inherently random as are many other processes in the Universe. This is not subjective.

You can introduce uncertainty by not bothering to find out the exact answer. How many hairs on a cats tail? I wont count but will estimate based upon information, perhaps. Is this the same as randomness? It seems different (errors) yet I could define a range of outcomes and assign each a probability?

Any situation where you could place a bet...'I bet there 100K hairs on a cats tail', 'I bet the coin will come  up tails', 'I bet the next car passing my window will be silver'.

The point is, you cannot be certain before (physical limits or can't be bothered) but will be certain in the end.

I add that we could replace 'in the end' with 'after the next step'. Life 'repeats' infinitely often, we wake up and start each day uncertain about the next 24 hours, are certain of what happened at the end and so the whole process repeats. By repeating an experiment over and over you get what's called a 'stochastic process'.

The key points are that the experiment or game hasn't finished and we have some reason to be uncertain about the possible result. In fact, in the world of probability theory the experiment can never end because once it does there is no more uncertainty about the outcome and we can swtich to statistics. So we must adopt a position of perpetual waiting and excitement for the coin to land heads or tails.

So let us repeat:

* the end of the game is in the future
* there is more than one possible result
* we are uncertain which of those results will occur

## Sample point
A sample point is a single *possible* result of a prediction, estimation, measurement, experiment, game or guess. Sample points come from varying fields of study and have different dimensions (seconds, hours, kg, ly,...). Of course, the sample points are of indisputable interest and the raison d'etre for the experiment or game itself. Our personal and professional conversations are full of possible prognostications, forecasts and predictions about future sample points:

* Interest rates will probably increase by 0.25% (possible result)
* The horse "d'Alembert's confusion" will probably win (possible result)
* The next F1 pit stop will probably be less than 2.5 seconds (possible result)
* The shopping website will probably not crash (possible result) on Black Friday.

[Consultants, 'talking-heads', executives and politicians are paid large sums of money to remove the word 'probably' from such statements. But uncertainty is part of the fabric so that's 'probably' not a good thing.] 

Yet perversely, probability theory has no interest whatsoever in the possible raw outcome itself. This is its power. It (as an axiomatic theory we shall ignore the fact many flavours exist) reveals hidden laws behind uncertainty in ANY experiment or game we can imagine and design - no matter what the sample points shape or size. Hence the first thing we will do is abstract away from any particular dimension or measure and introduce the mathematical variable $\omega$.

Symbolically, the label $\omega$ is used to represent ONE of the range of possible results that could have occurred - without specifying which one. So in mathematics, any statement using the symbol $\omega$ that is considered true automatically applies to any single value $\omega$ can take. This is not the same as saying $\omega$ represents a range of values - it doesn't, only one value in that range. But there is a subtle point here. Let's say your predicting the final score of your favourite soccer team. Writing $\omega=2$ could mean the game finished and now you know the actual value of $\omega$ for your next calculations. But in probability the experiment is not finished so how can we know $\omega=2$? Instead $\omega=2$ represents one of many possible futures as in 'what if the final score were 2'. Now we can sensibly write 'the probability $\omega=2$ is 1/3' to mean 'the probability of the future in which my favourite team scores 2 goals is 1/3'.

Having said all that there is another perversity that subtly creeps into probability theory. The sample point itself carries no information of any real interest. It will be the probability of it taking some value in some future world that is of real interest. In fact advanced texts in, for example, stochastic processes often spend little to no time worrying about what it represents. Again, it will be the probability models we are most interested in.

We now look at the phrase 'all possible values'. It is here that we find a key differentiator for advanced mathematical treatments of probability.


## Sample Space
Before we talk about a single outcome from a future experiment we must define the range of possible values $\omega$ can take. This forces us to be precise and opens our thinking up to mathematical treatment. Mathematics has a natural home for collections of things - the set. Just as we used the label $\omega$ to specify some single possible outcome, we use the label capital $\Omega$ to indicate the mathematical set of all possible outcomes. Using basic set notation, $\omega$ takes a value from within the set $\Omega$ is denoted $\omega \in \Omega$.

If you remember, $\omega$ should be thought of as representing a single outcome - without saying which outcome it represents. Likewise, $\Omega$ represents all possible outcomes from a single experiment - without saying which experiment it represents. $\Omega$ ranges across different experiments while $\omega$ ranges within a single experiment.

## Stuff TODO

Perhaps we should talk about 'not knowing' first. This is different from 'rational subjectivity' i.e. given all the information available (as per economics). Humans are not rational in many ways. So we must remove the natural mind from proceedings. 

Perhaps we can talk about equations as counterfactuals. Maybe even worldbuilding in the Pa, Pr, F? Perhaps we can present equations as timeless - they applied to games of dice played by ancient Greek philosophers, Roman centurions or distant alien cultures. But there has to be something common to all of these situations that demand we think differently?

Everything we talk about is in the future...about to happen. We're going to take this position but it can lead to some confusion given the nature of verb tenses.

Let's start with the present - where you are right now.

Consider the present. 'What is the capital of Zululand?'. 'I don't know but I wager it starts with a 'zeh''. We know an answer exists and has existed, so the uncertainty is about out ignorance of the future answer that is, no doubt, about to be revealed.

A coin is being tossed, a coin has been tossed, a coin was tossed, a coin will be tossed.
Pa->Pa, Pa->Pr, Pa->F. Pr -> Pa, Pr -> F. F ->Pa, F->Pr, F->F.

How heavy is the moon, who is the prime-minister of Nepal (choose from a list of 8 billion names), how many sweets in the jar, which door hides a car. The world and many people will know certain answers to these questions. But our protagonist doesn't. He can still wager given a set of possible answers.

Not knowing the answer when the answer exists, and not knowing an outcome when an experiment has not yet been conducted are treated as the same thing. It's the 'not knowing' that creates uncertainty.

This 'not knowing' can include the past 'I wager Caesar crossed the Rubicon on 4th March'. (Note: 'not knowing' what Caesar was thinking when he crossed the Rubicon and 'not knowing' what day Caesar crossed the Rubicon are fundamentally different in a way described below)

This includes the past. An elephant parachutes into our back garden...'what are the chances?' we muse. This actually means, going back in time five minutes before the outcome, pretending we're none the wiser, someone wagers $1M on an elephant parachuting into our back garden. We are imagining a counterfactual in the past but we're focused on the past-future.

But, we need to know our possible outcomes. But this might include 'a dog parachuting', 'a cat parachuting', 'a piece of airplane cowling falling down', 'a piece of meteorite', 'an alien spacecraft'. As you can see, we are only limited by our imagination. And that's the problem - asking about how many possibilities you could imagine just leads to a very long list - limited by our imagination. 

This is why we must use rather dull, so-called games: rolling a dice, rolling two die, spinning a coin. Now we can create well defined possible outcomes (though sooner or later, through boredom, imagination kicks back in and asks 'what if the coin landed on its edge, what if the dice rolled into a drain.).

So we must agree that everything is in the future from the point of view of the character involved and we ignore imagination and stick to well defined sets of possible outcomes.

Any experiment whose outcome is unknown given everything we know at the moment is called a random experiment. But we can describe all *possible observations* that can be made once the experiment is over. We cannot predict the outcome of tossing a coin but we know all the possible outcomes. Describe outcomes as relative to the experimental point of view and question being asked - an experiment does not  have a unique set of outcomes but there are many. So you might ask for the symbol on the coin after a toss, or whether it was the same as the toss before, or stock price vs delta, or pass/fail vs exact measurement of something, or intervals $\Delta t_i$ during which a component might fail (each interval is a sample point).

Also, randomness is relative to your state of knowledge - ask the next person you see their height and the answer is random from your perspective, even though that person was certain about their height before hand. However, the process by which the person was selected must be random (you cannot predict who will be chosen) otherwise there is no uncertainty.

How does mathematics model the results of an experiment? There are three separate ideas to keep in mind. Firstly, when is the experiment or trial considered finished? This can be subtle. For example, tossing a coin an inifinite number of times! The next idea is what possible results will you  actually record. This is the raw underlying data that can result from the experiment. For example, one trial tosses a coin three times and I observe HTH. The final point is a function of the possible observed results. This is a way of grouping the raw data to indicate that any of those results is of interest. 

Group all dice events that are even. Group all tosses with one, two, three heads. We consider the event to have occurred when one of those atomic outcomes occurs.

The experimenter may only be interested in what the data implies. Maybe they only want to know if the dice was odd or even - nothing else is of interest. The raw data is only useful in so far as it indicates with of the two events of interest occurred.

Another way to look at it is by how much information is revealed to the experimenter. Perhaps they can only distinguish from the particular experiment which group of numbers (even or odd) occurred at the end of the experiment. In this case, we can model the 'granularity' of the apparatus. Even though the possible results are known, perhaps only a certain amount of information was revealed by the apparatus.

Say the even numbers are red dots and the odd numbers blue dots. Say the apparatus can only distinguish red or blue. It cannot report the actual number so the experimenter is testing at a coarser level.

Explain difference between experiment where result is revealed at the end, and one where information is revealed as we go forward.

Of course, the apparatus is also limited in a more fundamental way. It cannot see into the future therefore cannot report the next step let alone the final outcome. The grouping of final outcomes is 'dynamic' in the sense that as each step is taken through time, the final outcomes can be regrouped given what just happened. For example, at the start of a coin tossing run, the final sequence could start with T or H. Once the first toss is completed the reported result (obviously, this is not a final outcome) groups the final outcomes into those that cannot and those that possibly could happen.

This is useful in modeling infinite events - those that reveal information over time. You never know the final outcome, only as much as the apparatus (in this case restricted by time) allows you to see. Think of a stock price. You can say something about what it wont do because those outcomes could not occur because they don't match the past information.

## Events
Let us introduce a simple example. 

Let's say we plan to run an experiment which will finish after a coin will have been tossed three times and the result will have been recorded as a string e.g. 'HTH'. What does the sample space look like? We know it's a set that contains all possible outcomes:
$$\Omega=\{HHH, HHT, HTH, HTT, TTT, TTH, THT, THH\}$$
Before we go any further, let's remember some interesting things about sets. You can form subsets, unions, complements and intersections between sets. Since $\Omega$ is a set how might these operations help? Here are some examples including possible prose describing those sets:

* $\{HHH\} \subseteq \Omega$
    * 'three heads', 'no tails'
* $\{HTT\} \subseteq \Omega$
    * 'only first toss will be heads', 'only last two tosses will be tails'
* $\{HHH\} \cup \{TTT\} = \{HHH, TTT\} \subseteq \Omega$
    * 'we'll find either all heads or all tails', 'all the tosses will be the same'
* $\{HHH\}^\complement \subseteq \Omega$
    * 'they won't all be heads'
* $\{HTT, THT, TTH\} \subseteq \Omega$
    * 'the result will have only one head', 'we will find exactly two tails'

Why is this useful? In advanced probability you will mostly make statements about collections, intervals or regions of the outcome space rather than any single outcome point itself. In fact, there are deep technical reasons why this becomes unavoidable if the outcome space is continuous in which case you cannot make sensible probability statements about a single sample point. But armed with the above set operations you can construct subsets of $\Omega$ about which you can make precise statements. These subsets are at the heart of formal probability theory and are so important that they are given a specific name - 'event'.

Warning! You will notice I have used the terms experiment, game, prediction etc to denote that which produces a random outcome. I have not used the term 'event' which in common parlance could be used to denote any of these moments in time. We shall reserve the term event to exclusively denote a subset of the outcome space. We will not say things such as 'what is the probability of a win after the (sports) event'.

And now we get to the crux of the matter. An outcome point is written 'HHT' or '1 second' or '6' etc, etc. But it's a very domain specific quantity. The problem is that very soon we're going to need some way to measure the 'probabilistic weight' of an outcome - the heavier it is the more probable it is - without caring about the outcomes definition. We therefore wish to disencumber ourselves of real world concerns such as units etc. Enter the event. By collecting outcomes into sets we trigger a whole ready and waiting branch of mathematics called measure theory. This branch of mathematics allows us to develop an abstract machine that weighs sets without ever knowing anything about the nature of the contents! It does this by assigning a size to a set that is related to the 'volume' of its contents. This is an incredibly powerful branch of mathematics that deals with continuous outcome spaces, their tremendous anomalies and the mathematical monsters hidden within the continuum. We won't pursue this topic in depth but much of the structure you see (sets, set operations, events) are the surface structures of some very deep intellectual icebergs.


THIS IS CORRECT MOTIVATION
Need to explain sample space and subsets (events) and atomic events.

Now what is the outcome after the experiment? Of course you don't yet know because 'chance' stands between you and the final result. But let's wind forward in time where we will find the result has been the subset $\{HTT\}$. Is there any uncertainty about the outcome anymore? Of course not - this is the land of statistics! 

Now, returning back to before the experiment has begun, we can assign a number to each possible outcome to indicate its probability of occurring. We can then write a set function $P(\{HHT\})=1/8$ to give an indication of how likely to be observed after our experiment is this possible result.

However, we also want to ask about the probability of events such as 'all results starting with H' or 'all results ending with two T'. So our set function must handle subsets such as $\{HHH, HHT, HTH, HTT\}$. In fact, we shall call all valid sets 'events'. So pretty much all subsets of the set of all possible outcomes, are events that can be used as an input variable to $P()$.


Things to notice. We no longer talk about 'outcomes' but talk about events. Each atomic event is one or more outcomes wrapped in a set. 

Motivate sigma-algebra. We want to talk about complex events. Consider the event of rolling a dice. Here are some descriptions of events. A number. An even number. An odd number. A multiple of 2. Divisible by 2. A prime number. Any number less than 3. Any number greater than 3. A number divisible by 6. 

We also have complex events such as: not the numer 6. The number 1 and the number 3. The number 1 or the number 3. 

Any combination of events through 'and', 'or', 'not' produces equivalent classes of events. 

## Filtration
Imagine the roll of a dice. However, after the experiment the result will not be given but revealed in response to three consecutive questions. For example, we might ask:

- Was the dice rolled?
- Having been told the dice was rolled, is the result odd or even?
- After being told the dice was rolled and the number was even, is it number 2?

The key property is that each question requires an answer that reveals more information than the question before. In other words, the responses become more 'granular' in some way. Let us use sets of events (sets of subsets of $\Omega$) to model all possible answers at each step:

$$\{\{1,2,3,4,5,6\}, \emptyset\}$$
$$\{\{1,3,5\}, \{2, 4, 6\}\}$$
$$\{\{1\},\{2\},\{3\},\{4\},\{5\},\{6\}\} $$
Notice, knowing which of the events in the last set occurred gives more granular information that knowing which of the events in the second set occurred. Likewise, knowing which of the events in the second set occurred gives more granular information than being told which of the events in the first set occurred. The above three sets are therefore modeling information flow over time - in some sense, information is increasing.

Of course our sequence of sets of events models all the possible ways information could be revealed given the above questions. An actual realization might be the following: 

* $\{1,2,3,4,5,6\}$ occurred (tells you a result has been discovered but not which one)
* $\{2, 4, 6\}$ occurred (tells you the final result is an even number)
* $\{4\}$ occurred (as much information as you could be given).

Another realization might have been $$\{1,2,3,4,5,6\} \rightarrow \{4,5,6\} \rightarrow \{5\}$$

However, we only look at realization paths as examples - our interest is modeling the sets of all possible answers at each step. This is probability after all and not statistics.

So let's return to modeling 'all possible answers'. Up until this point one of our questions is rather limiting, namely 'is the number odd or even'. Surely, we should be able to ask 'is the number divisible by 3?', 'is the number prime?' depending upon our experiment. 

So to take the next step, we're going to generalize and declare that at step 2 any question is allowed whose affirmative answer involves a set of two or more outcomes. This ensures we are still uncertain as to what could happen in step 3. In contrast, any question at step 3 requires an affirmative answer returning a single outcome e.g. 'is the number divisible by 6?'. This ensures there is no more uncertainty and the experiment has ended.

So how can we model the set of all possible events at a given level of granularity. Well the mathematical foundation of probability theory is measure theory which in turn rests on set theory. One of the wonderful bridges between the later two worlds is the a structural wonder known as a $\sigma$-algebra. This gets us into technical mathematics so we will only intuit its structure.

Simply put, if you have, say, two sets and list every union, intersection and complement between them, then you can collect each of those results into a super-set called the $\sigma$-algebra generated by those two sets. Let's form the required super-set at each stage of the revelation: 
$$S_1 = \{\{1, 2, 3, 4, 5, 6\}, \emptyset\}$$
That's all we can write for this first $\sigma$-algebra. Let's look at the $\sigma$-algebra generated by events of two or more outcomes:
$$S_2=\{\{1,2\}, \{1,3\}, \{1,2,3\}, \{2, 4, 6\},\dots, \{1,2,3,4,5,6\},\emptyset\}$$
Note: this includes atomic outcomes (e.g. $\{1,2\}\cap\{1,3\}=\{1\}$). But that doesn't matter as long as $S_2$ includes all possible events with two or more outcomes as required. Next, we model all possible ways of obtaining a single outcome using a $\sigma$-algebra:
$$S_3=\{\{1\},\{2\},\{3\},\dots, \{1,2\}, \{1,3\},\dots,\{1,2,3\},\{2,4,6\},\dots,\{1, 2, 3, 4, 5, 6\}, \emptyset \}$$
Note: again, we may have more events than required such as $\{1,2,3\}$ but there is a deeper reason for why that must be the case (modelling contains).

THIS EXAMPLE HAS FAILED BECAUSE $S_2=S_3$. The sigma algebra generated by both $\{a,b\}$ and $\{a\}$ are equal. Can I continue? Does filtration still have meaning if both sets are equal? No, I cannot continue. If the the two sigmas are the same, then each step contains the same information - nothing extra is revealed. So we must use the roll of two dice instead.
TODO: start with s1 and s2 for single dice. Then expand to S3 for two dice.
I think this is because after the single roll, there is no more uncertainty...how the hell did the sigma know that? Whereas with two dice, there is still uncertainty over the second roll. So my approach (revealing information) is not equivalent.

It is the relationship between $\sigma$-algebras that will be used to capture 'contains'. 

But, importantly, since the experiment has ended and I am revealing the result a step at a time, then each step must contain the final result $\{4\}$ (or $\{5\}$ in second case). In fact, each revelation must contain the next revelation in some way. This means the following can never occur as a revelation path: $$\{1,2,3,4,5,6\} \rightarrow \{1,3,5\} \rightarrow \{6\}$$ In words, I can't reveal 'the final number is odd' and in the next step reveal it was $6$.

  
As 'atomic events' are contained within the original set, every possible other subset that can be generated using union, intersection and complement is also a member of this $\sigma$-algebra, that's the whole shebang. Now notice we can write 'contains' using the subset relation: $$S_0 \subseteq S_1 \subseteq S_2$$

This is the way in which 'information revealing' is modeled using sets. As we arrange a sequence of $\sigma$-algebras using containment $S_0 \subseteq S_1 \subseteq S_2 \subseteq \dots \subseteq S_n$ each step allows us to model a narrowing down to the final result i.e. each step across time  models the arrival of information which leads to a reduction in uncertainty.

Another way to look at this is 'after each step we know which of the previous possibilities will never occur'. Once we are told 'odd number occurred' then we know 'even number never happened and can forget about that possibility. This is perhaps more useful when thinking about infinite sequences as there's always (for all time and beyond) a huge arrange of future possibilities, yet definite knowledge that some previous possibilities can now never occur.

[Another way to think about this is as the resolution of our measuring instrument. Perhaps even numbered dots are gold and odd number silver and at step 2, our measuring instrument can only resolve colour. What about measuring the colour of a star...resolution means being able to discriminate between individual outcomes vs groups of outcomes? Is 'resolution' a good physical metaphor for $\sigma$-algebra generated by $X$ is smallest $\sigma$-algebra...etc?]

## Probability
[Note: Oksenda: probability measure $P()$ is defined on the underlying sample space. Every random variable induces a probability measure $\mu_X$ on the range $\textbf{R}^n$ of $X$ $$\mu_X(B)=P(X^{-1}(B))$$. $\mu_X$ is called the DISTRIBUTION of $X$]

It is associated with events i.e. sets of sample points. Mathematically, probability is a weighting given to a the set containing a sample point that indicates the probability of it occurring in the upcoming experiment. 

Later on the common notation $P(X=x_k)$ will confuse matters. In reality, the probability function is defined on the domain (sample space) of a random variable. But it is often used as though $P()$ is defined on the range of the random variable. This is usually fine but always keep in mind the probability is a function taking a set of sample points as input.



## Random Variable
### Abstraction
We want to be able to make mathematical statements in our formal model and not talk about genders at birth, sides of a coin or something else. Mathematics allows us to abstract by using numbers to represents outcomes e.g. $Male=0, Female=1$ or $Heads=0, Tails=1$. In fact, by simply using $0,1$ to represent outcomes we no longer have to make statements within a subject domain. Instead of saying 'probability of a male' or 'probability of heads' we can say 'probability of getting 0'. Any experiment with a binary result can be modeled as a 0 or 1.

In other cases we may wish to process the result of the experiment. Take the roll of a dice. We might ask 'probability of an even number'. There are three even numbers on the dice. We are not distinguishing between them but grouping them into one set. We are only interested in the two qualities of odd/even. So we can map each number to either 0 or 1. Notice, we have abstracted away each number and only focus upon a single property of each number.

Another example comes from the tossing of three coins. Given an outcome, we might instead report the number of heads found in the result. This number ranges from 0 to 3. 

In many cases, the observation is already a number, for example when counting the number of people queuing at a supermarket. In this case, the conversion may leave the number as-is.

To map from H to 0 and T to 1 we use a mathematical function. So let us write $f(\omega)$ to represent this 'act of measurement'. The $\omega$ represents that which was observed (H or T) and $f(\omega)$ is the value of the measurement (0 or 1). Or the function might map $\{HHH\}$ to $3$ and $\{THH\}$ to $2$.

There is nothing at all random about this function. If you break it apart and peer inside you'll see the exact same mechanics as any other function such as $x^2$ or $sin(x)$. Nothing, nada, say no to randomness.

And yet a 'random variable' is defined as a function - so what gives?

Let us consider the moment after an experiment is run. Then you can plug an exact value for $\omega$ and out pops the corresponding measurement. However, as probabilists, we want to make statements before the experiment is run. But, in that moment, $f(\omega)$ has no value because no outcome has been recorded and $\omega$ has unknown value. So we can't actually use the function the way we can $x^2$ or $sin(x)$.

Instead, let's examine what we do know even before the experiment is run. As we have said, from the description of the function (H maps to 0 and T maps to 1) we know exactly how the function WILL behave when the experiment ends and an exact value for $\omega$ is observed. But at this point we are uncertain as to whether the input is going to be H or T. So both are *possible input values* to $f(\omega)$ but we are uncertain which one will materialize. So all we can say at the moment is that our simple function is pulsing with excitement waiting for any of the *possible input values*. And it is in this state of excitement and pulsation that a function levels-up and is renamed a random variable. In this state, we cannot say $\omega$ has value H or T. But we can say $\omega$ could take any of the *possible values* H or T. Bear this in mind as we will write $\omega = H$ to indicate we are considering the hypothetical future in which $\omega$ has possible value H instead of possible value T. When we use $\omega = H$ to indicate the experiment has ended and we observed the value H then we shall make it clear in the text.

There is one remaining problem we have to tackle. When we say *possible values* for $\omega$ we need some way to acknowledge that some things are more possible than others, or equally likely. This assignment of possibilities will need to be numeric to keep mathematicians happy. Naturally we're talking about probability and 'assignment' should bring us back to the notion of a mathematical function. So we will need a function that assigns to an outcome a probability. But what is the domain of this probability assignment function? Is it the sample space H or T, or is it the measure space 0 or 1. Well mathematics doesn't want to talk about heads or tails or the colour of geese. You can now see the whole purpose of $f(\omega)$ was to abstract away from the real world. $\omega$ comes from some range of outcomes - don't really care what. The key point, mathematically, is whether it is a continuous or discrete range of values. Given this emphasis, it  means our probabilities should be assigned to the values in the range space of $f(\omega)$. Since $f(\omega)$ maps to a single value, this presents no real problems. It is a subtle point worth keeping in the back of your mind that we're always writing $P(f(\omega))$.


Here's another example of converting things to numbers using functions. Here is our function, pulsing in excitement of its input value. Let's create another function $g(x)$ which maps a measurement such as 0 or 1 to a number less than one. In our case, we decide to assign $g(0)=1/2$ and $g(1) = 1/2$. Again, this function works on the measurements (0, 1), not the outcomes (H, T).

It is the pair $f(\omega)$ and $P(x)$ that warrants leveling-up $f(\omega)$ to the new title 'Random Variable'.

The point is that within the mathematics there is no randomness. There is no switch that says 'this function is deterministic but this one is random'. All functions are deterministic so all of 'normal mathematics' can be applied. It is only in the interpretation, the mental viewpoint -BEFORE- the experiment that the function is taken to model everything that could happen - but hasn't yet occurred. Here input values must be treated as possible input values and that randomness requires two function in a pair to model chance. Namely the random variable and the probability distribution of its range of values.

## Two random variables
A single experiment involves making two measurements, not just one. We will need two random variables to describe the output values, $X(\omega), Y(\omega)$. In this case, we could be making two measurements from a single outcome or two measurements from two separate outcomes (per experiment), it makes no difference. We have abstracted away from the actual outcome space to an abstract space to which we assign probabilities.
We just need a way of describing the possible results using an outcome space. So picking one person at random could result in a weight and height number. Each can be described by a random variable. Or we could toss a coin and spin a dice. We just need to describe the outcome space as we are not concerned with dependence of independence at this stage. Just need to describe all possible measurements form each experiment.

### Distribution
Only by assigning probabilities can we describe relationships between the outcomes and capture whether they are dependent or independent events per experiment.

The simplest case is the probability of getting one result and another $P(X=x, Y=y)$.

The second case is the probability of getting one result, given we have information on the other RV $P(X=x | Y=y)$. This latter captures an update in our assesmennt of probability in light of new information.




## Stochastic Process
$X(t, \omega)$

We're measuring a process - something that evolves over time. We could repeatedly measure the length of a table or count the number of keys on a keyboard and find it has the same value over time.
We could count the number of people in a supermarket every 5 minutes or measure the temperature of the sun every second, the price of a stock every hour, the amount of solar radiation reflected by the earth's atmosphere every year. 
I could record the result of flipping a coin, record the result of tossing a dice, measure my height, count the number of clouds in the sky...etc. Each is a measurement made at a different time - more of a survey of what's around me each moment than a process.

It's easier to grasp the final outcome of a process. This is known as a path or trajectory so let's look at some examples, each experiment lasting 5 units of time (seconds, minutes, hours,...) and each measurement carried out after one unit of time:

* Table length (week): 180cm, 180cm, 180cm, 180cm, 180cm
* Keys on keyboard (month): 104, 104, 104, 104, 103
* People in a shop (5 min): 35, 38, 33, 35, 32
* Surface sun (year): 5778K, 5670K, 5780K, 5560K, 5500K
* Coin flipping (flips): H, H, H, T, H
* Dice tossing: 1, 3, 2, 5, 4

Notice each path above measures something different. The range of possible values in each step is called the outcome space. For the first toss of a coin it might be H or T. But we will treat the state space as an entire path. So, [H, H, H, T, H] and [T, T, T, H, T] are two sample paths or outcomes of the process.

Each step is modeled using a function $X_t(\omega)$ where $\omega$ is a possible path that could be observed at the end of the run. $X_t$ is the function that maps the final path to what occurred at prior time $t$.

So where is the randomness? Let's start with a contrast and go to the comfortable scene at the end of the experiment when everything is known and randomness is no more. From the records you now see the entire path, so the input variable $\omega$ has attained a value and is now a constant - its value is written in the history books of this experiment forever. Let's pretend $\omega=(H,H,H,T,H)$. Using hindsight we can now write our function as $X(t, (H, H, H, T, H))$ showing the only input variable is now $t$ so at some past time, say $t=3$, $X(3, (H, H, H, T, H))=T$. The function maps from the known sequence $\omega$ to its value at time $t$.

This should be comfortable territory for those how understand basic mathematical functions.

Now let's work back one step in time. Let's pretend we don't know the final result but we do know at $t=3$ we've followed the path $(H, H, H, T, ?)$. The question mark shows our new perspective has introduced uncertainty but only about the last step. However, our definition of the master random variable requires a complete path as the last parameter $X(t, \omega)$. But we do not know the complete path as the experiment has not finished. So what use is the function $X(t, \omega)$ before the experiment has finished? This is where the functions partner in crime makes a reappearance. Let us look into the future and consider the current options for the final $\omega$? Obviously there are only two namely $(H, H, H, T, H)$ and $(H, H, H, T, T)$. Given we don't know which of the two will occur we have to somehow represent the current uncertainty about these two possibilities? Remember, a map stops being a common function and levels-up to being a random variable when it's paired with a probability distribution. It is this distribution that models our uncertainty. In this case the two final paths are equally likely so we provide the *additional information* $P(X(4, (H, H, H, T, T))) = 1/2$ and $P(X(4, (H, H, H, T, H))) = 1/2$.

Notice, there is no uncertainty associated with the current step. So $P(X(3, (H, H, H, T, T))) = 1$ and $P(X(3, (H, H, H, T, H))) = 1$. Uncertainty has has given way to certainty.


## Central Limit Theorem
What does this theorem actually say. 

## Expected Value
Calculation is same as statistical mean or statistical average. But it is performed pre-experiment. It shows the future average and indicates centre of gravity for distribution of masses, drift, bias that will be found in the results. It indicates the tendency of results to centralise around some value if repeated trials.
